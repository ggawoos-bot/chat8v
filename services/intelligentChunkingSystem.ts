/**
 * ì§€ëŠ¥í˜• ì²­í¬ ë¶„í•  ì‹œìŠ¤í…œ
 * ì˜ë¯¸ ë‹¨ìœ„ ì²­í¬ ë¶„í•  ë° ë¬¸ë§¥ ë³´ì¡´
 */

import { Chunk } from '../types';

export interface SemanticChunk extends Chunk {
  semanticInfo: {
    topic: string;
    concepts: string[];
    sentiment: 'positive' | 'negative' | 'neutral';
    importance: 'high' | 'medium' | 'low';
    contextPreserved: boolean;
  };
  chunkType: 'sentence' | 'paragraph' | 'topic' | 'section';
  boundaries: {
    startSentence: number;
    endSentence: number;
    startParagraph: number;
    endParagraph: number;
  };
}

export interface ChunkingOptions {
  maxChunkSize: number;
  minChunkSize: number;
  overlapSize: number;
  preserveSentences: boolean;
  preserveParagraphs: boolean;
  preserveTopics: boolean;
}

export class IntelligentChunkingSystem {
  private static readonly DEFAULT_OPTIONS: ChunkingOptions = {
    maxChunkSize: 2000,
    minChunkSize: 100,
    overlapSize: 200,
    preserveSentences: true,
    preserveParagraphs: true,
    preserveTopics: true
  };

  /**
   * ì§€ëŠ¥í˜• ì²­í¬ ë¶„í•  ì‹¤í–‰
   */
  static async performIntelligentChunking(
    content: string,
    metadata: any,
    options: Partial<ChunkingOptions> = {}
  ): Promise<SemanticChunk[]> {
    const chunkingOptions = { ...this.DEFAULT_OPTIONS, ...options };
    console.log(`ğŸ”„ ì§€ëŠ¥í˜• ì²­í¬ ë¶„í•  ì‹œì‘: ${content.length}ì`);
    
    try {
      // 1. í…ìŠ¤íŠ¸ êµ¬ì¡° ë¶„ì„
      const textStructure = this.analyzeTextStructure(content);
      
      // 2. ì˜ë¯¸ì  ë‹¨ìœ„ ì‹ë³„
      const semanticUnits = this.identifySemanticUnits(content, textStructure);
      
      // 3. ì²­í¬ ê²½ê³„ ê²°ì •
      const chunkBoundaries = this.determineChunkBoundaries(
        semanticUnits,
        chunkingOptions
      );
      
      // 4. ì˜ë¯¸ì  ì²­í¬ ìƒì„±
      const semanticChunks = this.createSemanticChunks(
        content,
        chunkBoundaries,
        metadata,
        semanticUnits
      );
      
      // 5. ì²­í¬ í’ˆì§ˆ ê²€ì¦
      const validatedChunks = this.validateChunkQuality(semanticChunks);
      
      console.log(`âœ… ì§€ëŠ¥í˜• ì²­í¬ ë¶„í•  ì™„ë£Œ: ${validatedChunks.length}ê°œ ì²­í¬`);
      
      return validatedChunks;
      
    } catch (error) {
      console.error('âŒ ì§€ëŠ¥í˜• ì²­í¬ ë¶„í•  ì˜¤ë¥˜:', error);
      throw error;
    }
  }

  /**
   * í…ìŠ¤íŠ¸ êµ¬ì¡° ë¶„ì„
   */
  private static analyzeTextStructure(content: string): {
    sentences: string[];
    paragraphs: string[];
    sections: string[];
    headings: string[];
  } {
    // ë¬¸ì¥ ë¶„í• 
    const sentences = content.split(/[.!?]+/).filter(s => s.trim().length > 0);
    
    // ë¬¸ë‹¨ ë¶„í• 
    const paragraphs = content.split(/\n\s*\n/).filter(p => p.trim().length > 0);
    
    // ì„¹ì…˜ ë¶„í•  (ì œëª© ê¸°ë°˜)
    const sections = content.split(/\n(?=[ê°€-í£]{2,}.*[:\-])/).filter(s => s.trim().length > 0);
    
    // ì œëª© ì¶”ì¶œ
    const headings = content.match(/^[ê°€-í£]{2,}.*[:\-]/gm) || [];
    
    return {
      sentences,
      paragraphs,
      sections,
      headings: headings.map(h => h.trim())
    };
  }

  /**
   * ì˜ë¯¸ì  ë‹¨ìœ„ ì‹ë³„
   */
  private static identifySemanticUnits(
    content: string,
    structure: any
  ): Array<{
    type: 'sentence' | 'paragraph' | 'section';
    content: string;
    startPos: number;
    endPos: number;
    topic: string;
    concepts: string[];
    importance: 'high' | 'medium' | 'low';
  }> {
    const units: any[] = [];
    let currentPos = 0;
    
    // ë¬¸ì¥ ë‹¨ìœ„ ë¶„ì„
    structure.sentences.forEach((sentence: string, index: number) => {
      const startPos = content.indexOf(sentence, currentPos);
      const endPos = startPos + sentence.length;
      
      const topic = this.extractTopic(sentence);
      const concepts = this.extractConcepts(sentence);
      const importance = this.determineImportance(sentence, concepts);
      
      units.push({
        type: 'sentence',
        content: sentence.trim(),
        startPos,
        endPos,
        topic,
        concepts,
        importance
      });
      
      currentPos = endPos;
    });
    
    return units;
  }

  /**
   * ì£¼ì œ ì¶”ì¶œ
   */
  private static extractTopic(text: string): string {
    // ê°„ë‹¨í•œ ì£¼ì œ ì¶”ì¶œ (ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ NLP í•„ìš”)
    const keywords = ['ì²´ìœ¡ì‹œì„¤', 'ì–´ë¦°ì´ì§‘', 'ê¸ˆì—°êµ¬ì—­', 'ë²•ë ¹', 'ì ˆì°¨', 'ê·œì •'];
    
    for (const keyword of keywords) {
      if (text.includes(keyword)) {
        return keyword;
      }
    }
    
    // ì²« ë²ˆì§¸ ëª…ì‚¬ ì¶”ì¶œ
    const nouns = text.match(/[ê°€-í£]{2,}/g);
    return nouns ? nouns[0] : 'ì¼ë°˜';
  }

  /**
   * ê°œë… ì¶”ì¶œ
   */
  private static extractConcepts(text: string): string[] {
    const concepts: string[] = [];
    
    // ë²•ë ¹ ê´€ë ¨ ê°œë…
    const legalConcepts = ['ë²•', 'ê·œì •', 'ì§€ì¹¨', 'ì•ˆë‚´', 'ì ˆì°¨', 'ìš”ê±´', 'ì¡°ê±´'];
    legalConcepts.forEach(concept => {
      if (text.includes(concept)) {
        concepts.push(concept);
      }
    });
    
    // ì‹œì„¤ ê´€ë ¨ ê°œë…
    const facilityConcepts = ['ì‹œì„¤', 'ì¥ì†Œ', 'ê³µê°„', 'ê±´ë¬¼', 'ì„¼í„°', 'ê´€', 'ì†Œ'];
    facilityConcepts.forEach(concept => {
      if (text.includes(concept)) {
        concepts.push(concept);
      }
    });
    
    // ê¸ˆì—° ê´€ë ¨ ê°œë…
    const smokingConcepts = ['ê¸ˆì—°', 'í¡ì—°', 'ë‹´ë°°', 'ë‹ˆì½”í‹´', 'ê¸ˆì§€', 'ì œí•œ'];
    smokingConcepts.forEach(concept => {
      if (text.includes(concept)) {
        concepts.push(concept);
      }
    });
    
    return [...new Set(concepts)];
  }

  /**
   * ì¤‘ìš”ë„ ê²°ì •
   */
  private static determineImportance(text: string, concepts: string[]): 'high' | 'medium' | 'low' {
    let importance = 0;
    
    // ê°œë… ìˆ˜ì— ë”°ë¥¸ ì¤‘ìš”ë„
    importance += concepts.length * 0.2;
    
    // í‚¤ì›Œë“œ í¬í•¨ ì—¬ë¶€
    const importantKeywords = ['ë²•ë ¹', 'ê·œì •', 'ì˜ë¬´', 'í•„ìˆ˜', 'ê¸ˆì§€', 'ì œí•œ'];
    const hasImportantKeywords = importantKeywords.some(keyword => text.includes(keyword));
    if (hasImportantKeywords) importance += 0.5;
    
    // êµ¬ì²´ì  ì •ë³´ í¬í•¨
    const hasSpecificInfo = /\d{4}ë…„|\d+ì¼|\d+%|\d+ì›/.test(text);
    if (hasSpecificInfo) importance += 0.3;
    
    if (importance >= 0.7) return 'high';
    if (importance >= 0.4) return 'medium';
    return 'low';
  }

  /**
   * ì²­í¬ ê²½ê³„ ê²°ì •
   */
  private static determineChunkBoundaries(
    semanticUnits: any[],
    options: ChunkingOptions
  ): Array<{
    startUnit: number;
    endUnit: number;
    startPos: number;
    endPos: number;
    chunkType: 'sentence' | 'paragraph' | 'topic' | 'section';
  }> {
    const boundaries: any[] = [];
    let currentStart = 0;
    
    while (currentStart < semanticUnits.length) {
      let currentEnd = currentStart;
      let currentLength = 0;
      
      // ìµœì†Œ ì²­í¬ í¬ê¸° í™•ë³´
      while (currentEnd < semanticUnits.length && currentLength < options.minChunkSize) {
        currentLength += semanticUnits[currentEnd].content.length;
        currentEnd++;
      }
      
      // ìµœëŒ€ ì²­í¬ í¬ê¸° ì œí•œ
      while (currentEnd < semanticUnits.length && currentLength < options.maxChunkSize) {
        const nextUnit = semanticUnits[currentEnd];
        if (currentLength + nextUnit.content.length > options.maxChunkSize) {
          break;
        }
        currentLength += nextUnit.content.length;
        currentEnd++;
      }
      
      // ì˜ë¯¸ì  ê²½ê³„ í™•ì¸
      if (options.preserveTopics) {
        currentEnd = this.adjustForTopicBoundary(semanticUnits, currentStart, currentEnd);
      }
      
      if (options.preserveParagraphs) {
        currentEnd = this.adjustForParagraphBoundary(semanticUnits, currentStart, currentEnd);
      }
      
      if (options.preserveSentences) {
        currentEnd = this.adjustForSentenceBoundary(semanticUnits, currentStart, currentEnd);
      }
      
      const startPos = semanticUnits[currentStart].startPos;
      const endPos = semanticUnits[currentEnd - 1].endPos;
      
      boundaries.push({
        startUnit: currentStart,
        endUnit: currentEnd,
        startPos,
        endPos,
        chunkType: this.determineChunkType(semanticUnits, currentStart, currentEnd)
      });
      
      // ì˜¤ë²„ë© ì ìš©
      currentStart = Math.max(currentStart + 1, currentEnd - Math.floor(options.overlapSize / 100));
    }
    
    return boundaries;
  }

  /**
   * ì£¼ì œ ê²½ê³„ ì¡°ì •
   */
  private static adjustForTopicBoundary(
    semanticUnits: any[],
    start: number,
    end: number
  ): number {
    // í˜„ì¬ ì²­í¬ ë‚´ì—ì„œ ì£¼ì œê°€ ë°”ë€ŒëŠ” ì§€ì  ì°¾ê¸°
    const startTopic = semanticUnits[start].topic;
    
    for (let i = start + 1; i < end; i++) {
      if (semanticUnits[i].topic !== startTopic) {
        return i;
      }
    }
    
    return end;
  }

  /**
   * ë¬¸ë‹¨ ê²½ê³„ ì¡°ì •
   */
  private static adjustForParagraphBoundary(
    semanticUnits: any[],
    start: number,
    end: number
  ): number {
    // ë¬¸ë‹¨ ê²½ê³„ë¥¼ ì°¾ì•„ì„œ ì¡°ì • (ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ë” ì •êµí•œ ë¡œì§ í•„ìš”)
    return end;
  }

  /**
   * ë¬¸ì¥ ê²½ê³„ ì¡°ì •
   */
  private static adjustForSentenceBoundary(
    semanticUnits: any[],
    start: number,
    end: number
  ): number {
    // ë¬¸ì¥ ê²½ê³„ë¥¼ ì°¾ì•„ì„œ ì¡°ì •
    return end;
  }

  /**
   * ì²­í¬ ìœ í˜• ê²°ì •
   */
  private static determineChunkType(
    semanticUnits: any[],
    start: number,
    end: number
  ): 'sentence' | 'paragraph' | 'topic' | 'section' {
    const unitCount = end - start;
    
    if (unitCount === 1) return 'sentence';
    if (unitCount <= 3) return 'paragraph';
    if (unitCount <= 10) return 'topic';
    return 'section';
  }

  /**
   * ì˜ë¯¸ì  ì²­í¬ ìƒì„±
   */
  private static createSemanticChunks(
    content: string,
    boundaries: any[],
    metadata: any,
    semanticUnits: any[]
  ): SemanticChunk[] {
    return boundaries.map((boundary, index) => {
      const chunkContent = content.substring(boundary.startPos, boundary.endPos);
      const unitsInChunk = semanticUnits.slice(boundary.startUnit, boundary.endUnit);
      
      // ì²­í¬ì˜ ì˜ë¯¸ì  ì •ë³´ ì§‘ê³„
      const topics = [...new Set(unitsInChunk.map(unit => unit.topic))];
      const concepts = [...new Set(unitsInChunk.flatMap(unit => unit.concepts))];
      const importance = this.aggregateImportance(unitsInChunk);
      const sentiment = this.determineSentiment(chunkContent);
      
      return {
        id: `${metadata.id || 'chunk'}_${index}`,
        content: chunkContent,
        metadata: {
          ...metadata,
          position: index,
          startPosition: boundary.startPos,
          endPosition: boundary.endPos,
          originalSize: chunkContent.length
        },
        keywords: concepts,
        location: {
          document: metadata.title || 'Unknown',
          section: topics[0] || 'general',
          page: metadata.page || 0
        },
        semanticInfo: {
          topic: topics[0] || 'general',
          concepts,
          sentiment,
          importance,
          contextPreserved: true
        },
        chunkType: boundary.chunkType,
        boundaries: {
          startSentence: boundary.startUnit,
          endSentence: boundary.endUnit,
          startParagraph: boundary.startUnit,
          endParagraph: boundary.endUnit
        }
      };
    });
  }

  /**
   * ì¤‘ìš”ë„ ì§‘ê³„
   */
  private static aggregateImportance(units: any[]): 'high' | 'medium' | 'low' {
    const importanceCounts = { high: 0, medium: 0, low: 0 };
    
    units.forEach(unit => {
      importanceCounts[unit.importance]++;
    });
    
    if (importanceCounts.high > importanceCounts.medium + importanceCounts.low) {
      return 'high';
    } else if (importanceCounts.medium > importanceCounts.low) {
      return 'medium';
    } else {
      return 'low';
    }
  }

  /**
   * ê°ì • ë¶„ì„
   */
  private static determineSentiment(text: string): 'positive' | 'negative' | 'neutral' {
    const positiveWords = ['í—ˆìš©', 'ê°€ëŠ¥', 'ì§€ì›', 'ë„ì›€', 'ê°œì„ ', 'í–¥ìƒ'];
    const negativeWords = ['ê¸ˆì§€', 'ì œí•œ', 'ë¶ˆê°€', 'ìœ„ë°˜', 'ì²˜ë²Œ', 'ë²Œê¸ˆ'];
    
    const positiveCount = positiveWords.filter(word => text.includes(word)).length;
    const negativeCount = negativeWords.filter(word => text.includes(word)).length;
    
    if (positiveCount > negativeCount) return 'positive';
    if (negativeCount > positiveCount) return 'negative';
    return 'neutral';
  }

  /**
   * ì²­í¬ í’ˆì§ˆ ê²€ì¦
   */
  private static validateChunkQuality(chunks: SemanticChunk[]): SemanticChunk[] {
    return chunks.filter(chunk => {
      // ìµœì†Œ ê¸¸ì´ í™•ì¸
      if (chunk.content.length < 50) return false;
      
      // ì˜ë¯¸ì  ì •ë³´ í™•ì¸
      if (chunk.semanticInfo.concepts.length === 0) return false;
      
      // ë¬¸ë§¥ ë³´ì¡´ í™•ì¸
      if (!chunk.semanticInfo.contextPreserved) return false;
      
      return true;
    });
  }

  /**
   * ì²­í¬ í†µê³„ ìƒì„±
   */
  static generateChunkingStatistics(chunks: SemanticChunk[]): {
    totalChunks: number;
    averageChunkSize: number;
    chunkTypeDistribution: { [key: string]: number };
    importanceDistribution: { [key: string]: number };
    sentimentDistribution: { [key: string]: number };
    topicDistribution: { [key: string]: number };
  } {
    const totalChunks = chunks.length;
    const averageChunkSize = chunks.reduce((sum, chunk) => sum + chunk.content.length, 0) / totalChunks;
    
    const chunkTypeDistribution = chunks.reduce((dist, chunk) => {
      dist[chunk.chunkType] = (dist[chunk.chunkType] || 0) + 1;
      return dist;
    }, {} as { [key: string]: number });
    
    const importanceDistribution = chunks.reduce((dist, chunk) => {
      dist[chunk.semanticInfo.importance] = (dist[chunk.semanticInfo.importance] || 0) + 1;
      return dist;
    }, {} as { [key: string]: number });
    
    const sentimentDistribution = chunks.reduce((dist, chunk) => {
      dist[chunk.semanticInfo.sentiment] = (dist[chunk.semanticInfo.sentiment] || 0) + 1;
      return dist;
    }, {} as { [key: string]: number });
    
    const topicDistribution = chunks.reduce((dist, chunk) => {
      dist[chunk.semanticInfo.topic] = (dist[chunk.semanticInfo.topic] || 0) + 1;
      return dist;
    }, {} as { [key: string]: number });
    
    return {
      totalChunks,
      averageChunkSize: Number(averageChunkSize.toFixed(2)),
      chunkTypeDistribution,
      importanceDistribution,
      sentimentDistribution,
      topicDistribution
    };
  }
}
